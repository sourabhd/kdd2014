{
 "metadata": {
  "name": "Document_embeddings"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pandas as pd\n",
      "import numpy as np\n",
      "import cPickle as pickle\n",
      "import scipy.sparse as sps\n",
      "from sklearn import linear_model\n",
      "import sklearn.preprocessing as pre\n",
      "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
      "from sklearn import linear_model, cross_validation,svm,naive_bayes,ensemble\n",
      "import re \n",
      "from sklearn.pipeline import Pipeline\n",
      "from time import time\n",
      "from operator import itemgetter\n",
      "from scipy.stats import randint as sp_randint\n",
      "\n",
      "from sklearn.grid_search import GridSearchCV, RandomizedSearchCV\n",
      "from sklearn.ensemble import RandomForestClassifier\n",
      "from itertools import izip\n",
      "import os\n",
      "import matplotlib.pyplot as plt"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def load_embeddings(vocab,wordVectors):\n",
      "    embeddings={}\n",
      "    for line_vocab,line_wordVectors in izip(vocab,wordVectors):\n",
      "        vect=line_wordVectors.split()\n",
      "        line_vocab=line_vocab.rstrip('\\n')\n",
      "        embeddings[line_vocab.lower()]=map(float,vect)\n",
      "    return embeddings\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def clean(s):\n",
      "        try:\n",
      "            return \" \".join(re.findall(r'\\w+', s,flags = re.UNICODE | re.LOCALE)).lower()\n",
      "        except:\n",
      "            return \" \".join(re.findall(r'\\w+', \"no_text\",flags = re.UNICODE | re.LOCALE)).lower()\n",
      "\n",
      "#donations = pd.read_csv('donations.csv')\n",
      "projects = pd.read_csv('projects.csv')\n",
      "outcomes = pd.read_csv('outcomes.csv')\n",
      "#resources = pd.read_csv('resources.csv')\n",
      "sample = pd.read_csv('sampleSubmission.csv')\n",
      "essays = pd.read_csv('essays.csv')\n",
      "\n",
      "\n",
      "essays = essays.sort('projectid')\n",
      "projects = projects.sort('projectid')\n",
      "sample = sample.sort('projectid')\n",
      "ess_proj = pd.merge(essays, projects, on='projectid')\n",
      "outcomes = outcomes.sort('projectid')\n",
      "\n",
      "#Create Labels\n",
      "le = pre.LabelEncoder()\n",
      "le.fit(outcomes['is_exciting'])\n",
      "outcomes['is_exciting']=le.transform(outcomes['is_exciting'])\n",
      "labels=outcomes['is_exciting']\n",
      "\n",
      "#Clean essay data \n",
      "ess_proj['essay'] = ess_proj['essay'].apply(clean)\n",
      "ess_proj_arr = np.array(ess_proj)\n",
      "\n",
      "#get train indx and test indx\n",
      "train_idx = np.where(ess_proj_arr[:,-1] < '2014-01-01')[0]\n",
      "test_idx = np.where(ess_proj_arr[:,-1] >= '2014-01-01')[0]\n",
      "\n",
      "#ESSAY training Data\n",
      "traindata = ess_proj_arr[train_idx,:]\n",
      "testdata = ess_proj_arr[test_idx,:]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": "*"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "'''LOAD THE EMBEDDINGS'''\n",
      "pwd=os.getcwd()\n",
      "vocab=open(pwd+\"/kdd2014/data/ACL2012_wordVectorsTextFile/vocab.txt\",'r')\n",
      "wordVectors=open(pwd+\"/kdd2014/data/ACL2012_wordVectorsTextFile/wordVectors.txt\",'r')\n",
      "embeddings=load_embeddings(vocab,wordVectors)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": "*"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#texts = [[word for word in document.lower().split() if word in embeddings.keys()] for document in traindata[:,5]]\n",
      "#pickle.dump(texts,open('document_tokens','wb'))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Cv=CountVectorizer(analyzer='word',lowercase=True,min_df=3,vocabulary=embeddings)\n",
      "Cv.fit(traindata[:,5])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": "*"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "vocab=Cv.vocabulary_.keys()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": "*"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#[vocab.remove(word) for word in vocab if word not in embeddings.keys()]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "KeyboardInterrupt",
       "evalue": "",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-21-1717c775fef2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;34m[\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvocab\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0membeddings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
        "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
       ]
      }
     ],
     "prompt_number": 21
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}